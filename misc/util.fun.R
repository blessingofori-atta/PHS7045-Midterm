library(foreach)
library(doParallel)

# Function to calculate the standard error of the sample mean
# Input: x - a numeric vector; na.rm - a logical value
statisticse <- function(x, na.rm = TRUE) {
  if (na.rm) {
    x <- x[!is.na(x)]
  }
  n <- length(x)
  se <- sqrt(var(x)/n)
  se
}

# Function to calculate and update the t-critical value
# Input: alpha - a numeric value indicating the significance level;
# B - a numeric value of the number of bootstrap samples
tcrit.fun <- function(alpha, B){
  crit <- (1 - alpha) * B
  if(!is.integer(crit)){
    crit <- floor((1 - alpha) *(B + 1))
  }
  return(crit)
}

#need to update
# Function to generate the bootstrap samples and calculate the bootstrap statistic theta
# nboot is the number of bootstrap samples
bootstrap <- function(x, xbar, nboot=1000){
  bsample <- matrix(sample(x, size = length(x) * nboot, replace = TRUE), nrow = nboot)
  #Calculate the bootstrap values of theta
  thetastar <- rowMeans(bsample)
  return(list(
    bsample = bsample,
    thetastar = thetastar
  )
  )
}


# Function to calculate the symmetric bootstrap-t confidence interval
# x: vector of the original sample
# xbar: sample mean
# thetastar: bootstrap values of the statistic
# bootsamples: bootstrap samples generated by the bootstrap function
# sdfun: opt ional name of function for computing the standard deviation of theta based on data x.
# If sdfun is missing, then symboott uses an inner bootstrap loop to estimate the standard deviation of theta(x).
# nboot: number of bootstrap samples
# nbootsd: number of bootstrap samples to estimate the standard deviation of theta(x)
# alpha: significance level
symboott <- function(x, xbar, thetastar, bootsamples, sdfun = NULL, nboot = 1000, nbootsd=25, alpha=0.05){
  #symmetric bootstrap-t method
  num <- thetastar - xbar
  n_size <- length(x)

  # [2024-11-15] George: I would move the cl object outside of the function
  # in case the user wants to provide their own. That will also imply not
  # stopping the cluster on exit.
  cl <- parallel::makeCluster(4)
  on.exit(parallel::stopCluster(cl))  # Ensure the cluster stops when function exits

  if(is.null(sdfun)){
    row_vars <- rowSums((bootsamples - rowMeans(bootsamples))^2) / (n_size - 1)
    denom <- sqrt(row_vars / n_size)

    if (any(is.na(denom))) {
      stop("Some values in denom are NA; check the statisticse function.")
    }
  } else {
    # Create a function to compute denom for parallel processing
    compute_denom <- function(i) {
      boot.sd.sample <- matrix(sample(bootsamples[i, ], size = nbootsd * n_size, replace = TRUE), nrow = nbootsd)
      boot.sd.theta <- rowMeans(boot.sd.sample)
      return(sdfun(boot.sd.theta))
    }

    # Parallelize the inner loop
    parallel::clusterExport(cl, c("bootsamples", "x", "sdfun", "nbootsd"), envir = environment())
    denom <- parallel::parSapply(cl, 1:nboot, compute_denom)
  }

  tstar <- sort(abs(num/denom))
  tcrit <- tcrit.fun(alpha, nboot)
  sdmean <- statisticse(x=x)
  c(xbar - tstar[tcrit] * sdmean, xbar + tstar[tcrit] * sdmean)
}



# Function to calculate the coverage of the confidence intervals for each of the 4 methods
cover.95 <- function(x, xbar, bootsamples, thetastar, alpha, mu){
  #symmetric bootstrap-t method with plugin estimate of standard error
  ci.symboott.plugin <- symboott(x=x, xbar=xbar, thetastar = thetastar, bootsamples = bootsamples, sdfun = NULL)

  #symmetric bootstrap-t method with bootstrap standard error
  ci.symboott <- symboott(x = x, xbar=xbar, thetastar = thetastar, bootsamples = bootsamples, sdfun = function(i) sd(i), nbootsd = 25)

  #percentile method
  ci.perc <- quantile(thetastar, c(alpha/2, 1-alpha/2))

  # #Wald method
  se_x <- statisticse(x=x)
  z <- qnorm(1 - alpha / 2)
  ci.wald <- c(xbar - z * se_x, xbar + z * se_x)

  return (
    cbind(
      symboott_plugin = all(mu > ci.symboott.plugin[1], mu < ci.symboott.plugin[2]),
      symboott = all(mu > ci.symboott[1], mu < ci.symboott[2]),
      perc = all(mu > ci.perc[1], mu < ci.perc[2]),
      wald = all(mu > ci.wald[1], mu < ci.wald[2])
    )
  )
}


# Function to simulate the mcreps of x for each n.
# Then, calculate the coverage of the confidence intervals for the 4 methods
simfun <- function(true.mean = 1, mcrep = 500, nobs, alpha = 0.05){
  sim <- rexp(nobs * mcrep, rate = 1/true.mean) # Simulate data
  #sim <- rnorm(n[3] * mcrep) # Simulate data
  xmat <- matrix(sim, ncol = mcrep) #each column is a replication
  xbar <- colMeans(xmat) # Compute the sample mean for each replication

  # [2024-11-15] George: This will likely fail in some scenarios (what if cores = 2?). Again, I recommend
  # moving the cluster object to be an argument of the function.
  cl <- makeCluster(detectCores()-3)

  # [2024-11-15] George: Are you sure you can't do this directly without the foreach R
  # package?
  registerDoParallel(cl)
  sim_results <- foreach(i = 1:mcrep,
                         .combine = rbind,
                         .export = c("bootstrap", "cover.95", "symboott", "statisticse", "tcrit.fun")
  ) %dopar% {
    # Generate nboot independent bootstrap datasets and compute the 95% coverage
    boot.res <- bootstrap(x = xmat[, i], xbar=xbar[i], nboot=1000)

    # Verify if the true mean is within the confidence interval
    sim_cover.95 <- cover.95(
      x = xmat[, i],
      xbar = xbar[i],
      bootsamples = boot.res$bsample,
      thetastar = boot.res$thetastar,
      alpha = alpha,
      mu = true.mean)
  }

  # Stop the cluster
  stopCluster(cl)

  #Return the average coverage rate across all replications
  return(colMeans(sim_results))
}


#============================================== Serial Function ==============================================

# [2024-11-15] George: The serial function should be the same as running the parallel
# function with a single core. You could later build a test that does that. It is
# a better approach as you are reducing the number of code lines to maintain.
simfun_serial <- function(true.mean = 1, mcrep = 500, nobs, alpha = 0.05){
  sim <- rexp(nobs * mcrep, rate = 1/true.mean) # Simulate data
  #sim <- rnorm(nobs * mcrep) # Simulate data
  xmat <- matrix(sim, ncol = mcrep) #each column is a replication
  xbar <- colMeans(xmat) # Compute the sample mean for each replication


  sim_results <- matrix(NA, nrow = mcrep, ncol = 4)
  for(i in 1:mcrep) {
    # Generate nboot independent bootstrap datasets and compute the 95% coverage
    boot.res <- bootstrap(x = xmat[, i], xbar=xbar[i], nboot=1000)

    # Verify if the true mean is within the confidence interval
    sim_results[i, ] <- cover.95(
      x = xmat[, i],
      xbar = xbar[i],
      bootsamples = boot.res$bsample,
      thetastar = boot.res$thetastar,
      alpha = alpha,
      mu = true.mean)
  }

  #Return the average coverage rate across all replications
  return(colMeans(sim_results))
}



coverage_serial <- function() {
  coverage <- matrix(NA, nrow = length(n), ncol = 4)

  for (i in seq_along(n)) {
    coverage[i, ] <- simfun_serial(nobs = n[i])

  }
  return(coverage) # Return the results
}


#BenchMark (Taking too long): Will revisit this
# microbenchmark::microbenchmark(
#   serial = coverage_serial(),
#   parallel = coverage_parallel(),
#   times = 10
# )


